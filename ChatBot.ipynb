{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wWc0yqx4cu4YaLKX8wwbXpSlEhffyms5",
      "authorship_tag": "ABX9TyN2i1aKjF2xEfz4FUK018hr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/drbarak/NLP-FinalProject/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB2riNzw6QD6",
        "outputId": "b8236b12-3c48-4a1b-de04-91c7bf85aed6"
      },
      "source": [
        "INSTALL = True\n",
        "if INSTALL:\n",
        "  !pip install pyforest\n",
        "  !pip install spacy\n",
        "  !pip install wget\n",
        "  !python -m spacy download en_core_web_md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyforest\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/ae/418f9bbcfb442bb6775f294451c97e134f84c8c4f47d75208419e4af7e13/pyforest-1.1.0.tar.gz\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.1.0-py2.py3-none-any.whl size=14606 sha256=838d064fd5116661c1488a413d9fcd607f3a9489421882cb4030b165d2ff4437\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/c6/da/43562aeea85b37f1a2b3d326f0f602f865000d2ada8a43625f\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.1.0\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp37-none-any.whl size=9675 sha256=30f152b5fa1c1664fc665c5373c9a39341499ac10f51d2a4be415714ee190fed\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Collecting en_core_web_md==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.5/en_core_web_md-2.2.5.tar.gz (96.4MB)\n",
            "\u001b[K     |████████████████████████████████| 96.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_md==2.2.5) (3.7.4.3)\n",
            "Building wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.5-cp37-none-any.whl size=98051304 sha256=5261e795d19703f25a588a056e220a13fe243d16bffdd186b94035dad507c8b7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lbq8sdy_/wheels/df/94/ad/f5cf59224cea6b5686ac4fd1ad19c8a07bc026e13c36502d81\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UENbsDfWvtF2"
      },
      "source": [
        "# INIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_gXeiB58h8k"
      },
      "source": [
        "from importlib import import_module\n",
        "def my_import(lib, package=None, func=None):\n",
        "  try:\n",
        "    import_module(lib)\n",
        "  except:\n",
        "    if package is None: package = lib\n",
        "    !pip install \"{package}\"\n",
        "    import_module(lib)\n",
        "  \n",
        "  if func is not None:\n",
        "    return import_module(lib).__getattribute__(func)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgpLToDvAC0z"
      },
      "source": [
        "my_import('pyforest')\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "p = print\n",
        "d = display"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opt4fUcLfvZ_"
      },
      "source": [
        "my_import('spacy')\n",
        "from spacy.tokens import Doc, Span\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# Load md (medium) English tokenizer, tagger, parser and NER, and vectors(vectors are not included in the 'sm' model)\n",
        "#nlp = spacy.load('en_core_web_md')  NOT WORKING ON COLAB\n",
        "try:\n",
        "  import en_core_web_md\n",
        "except:  \n",
        "  !python -m spacy download en_core_web_md\n",
        "  import en_core_web_md\n",
        "  \n",
        "nlp = en_core_web_md.load()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADlBlmyOBUnx",
        "outputId": "944e731c-892f-4d20-d69e-ebbd6ed5d8d5"
      },
      "source": [
        "nlp"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7fd76bb40e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdnCbXKo5cwo"
      },
      "source": [
        "import requests\n",
        "\n",
        "api_key = 'c2adfa29edfd95ad16efab9218619ff3'\n",
        "URL = \"http://api.openweathermap.org/data/2.5/weather?\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8DgeWTF03z"
      },
      "source": [
        "path = '/content/drive/MyDrive/Project5_ChatBot/'\n",
        "data_url = 'https://raw.githubusercontent.com/DanielKorenDataScience/NLP-FinalProject/main/data/' "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFqfk8lMh8x-"
      },
      "source": [
        "TEST = False"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJpv2GTU2-l7"
      },
      "source": [
        "def process_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    result = []\n",
        "    for token in doc:\n",
        "        if token.text in nlp.Defaults.stop_words:   # len(nlp.Defaults.stop_words)=326\n",
        "            continue\n",
        "        if token.is_punct:\n",
        "            continue\n",
        "        if token.lemma_ == '-PRON-':\n",
        "            p('-PRON-: ', token.lemma_)\n",
        "            continue\n",
        "        result.append(token.lemma_)\n",
        "    return \" \".join(result)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG99z-tM4cl4"
      },
      "source": [
        "def calculate_similarity(text1, text2):\n",
        "    def get_similarity(doc1, doc2):\n",
        "      if doc1 and doc1.vector_norm:\n",
        "        if doc2 and doc2.vector_norm:\n",
        "          return doc1.similarity(doc2)\n",
        "      return 0\n",
        "\n",
        "    doc1 = nlp(text1)\n",
        "    #p(doc1.pos_)\n",
        "    doc2 = nlp(text2)\n",
        "    similarity1 = get_similarity(doc1, doc2)\n",
        "\n",
        "    doc1 = nlp(process_text(text1))\n",
        "    #p(doc1)\n",
        "    doc2 = nlp(process_text(text2))\n",
        "    #p(doc2)\n",
        "    similarity2 = get_similarity(doc1, doc2)\n",
        "\n",
        "    return max(similarity1, similarity2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mS1pXmhO4ugH"
      },
      "source": [
        "# Call the web site"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhygq47xtL1r"
      },
      "source": [
        "{\"coord\":{\"lon\":34.8,\"lat\":32.0833},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02n\"}],\"base\":\"stations\",\"main\":{\"temp\":295.69,\"feels_like\":295.83,\"temp_min\":294.42,\"temp_max\":296.58,\"pressure\":1016,\"humidity\":70},\"visibility\":10000,\"wind\":{\"speed\":2.06,\"deg\":10},\"clouds\":{\"all\":20},\"dt\":1623961727,\"sys\":{\"type\":1,\"id\":6845,\"country\":\"IL\",\"sunrise\":1623897263,\"sunset\":1623948546},\"timezone\":10800,\"id\":293396,\"name\":\"Tel Aviv\",\"cod\":200}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQObVOJn-LGD"
      },
      "source": [
        "WEATHER_ONLY = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkn5WmrShACd"
      },
      "source": [
        "def call_web(city_name, country, count=1):\n",
        "    state = ''\n",
        "    api_url = f\"{URL}q={city_name},{state},{country}&cnt={count}&appid={api_key}\"\n",
        "    #p(api_url)\n",
        "\n",
        "    response = requests.get(api_url)\n",
        "    response_dict = response.json()\n",
        "\n",
        "    weather = response_dict #[\"weather\"]#[0]#[\"description\"]\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return weather\n",
        "    elif response.status_code == 404:\n",
        "        return None\n",
        "    else:\n",
        "        print('[!] HTTP {0} calling [{1}]'.format(response.status_code, api_url))\n",
        "        return None"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1XIdfNeh1d5"
      },
      "source": [
        "def get_weather(dt, location, action = None):\n",
        "  template = WEATHER_ONLY\n",
        "\n",
        "  city_w = city = location[0][0]  # assume one city (not handling ifthere are 2 cities)\n",
        "  #p(city, city_w)\n",
        "  result = ''\n",
        "  # check if city in api_city list\n",
        "  if city in df_CITIES_API.index.values:\n",
        "    result = df_CITIES_API.loc[city]\n",
        "  if len(result) == 0: # not found, get district\n",
        "    if city in cities_il_df.index.values:\n",
        "      city_w = cities_il_df.loc[city].district\n",
        "  elif len(result) > 0: # more than one city -> need country\n",
        "    pass\n",
        "\n",
        "  #p(city_w)\n",
        "  country = location[0][1]\n",
        "  country_code = countries_df[countries_df.Name == country].index[0]\n",
        "  \n",
        "  city_weather = call_web(city_w, country_code)\n",
        "  if city_weather is not None:\n",
        "    if template == WEATHER_ONLY:\n",
        "      result = city_weather[\"weather\"][0][\"description\"]\n",
        "    return f\"In {city.capitalize()}, {location[0][1].capitalize()} the current weather is: {result}\"\n",
        "  else:\n",
        "    return \"Something went wrong.\"\n",
        " \n",
        "#answer = get_weather('current', [('toronto', 'united states')])\n",
        "#answer"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMXfN0EnkL3a"
      },
      "source": [
        "# Get cities and update model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF2CJIu3pOik"
      },
      "source": [
        "GIT = True\n",
        "git_path = 'https://raw.githubusercontent.com/DanielKorenDataScience/NLP-FinalProject/main/data/'\n",
        "\n",
        "def get_json(fname, GIT=True):\n",
        "  p(fname)\n",
        "  if GIT:\n",
        "    resp = requests.get(data_url + fname)\n",
        "    return json.loads(resp.text)\n",
        "  with open(path + fname, encoding=\"utf8\") as f:\n",
        "    return json.loads(f.read())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyn9GTNLu_XA",
        "outputId": "8541b590-e6de-484b-8376-1b02b674e77f"
      },
      "source": [
        "intents = get_json('intents.json')\n",
        "#intents"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "intents.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVyPlh34vAJ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3bae82cd-0d9a-4ae0-8c25-8518c79b01b7"
      },
      "source": [
        "my_import('wget')\n",
        "import wget\n",
        "\n",
        "def load_CITIES_API():\n",
        "  # file too big for git so read it from my google drive using a shared link\n",
        "  #CITIES_API = get_json('city.list.json')\n",
        "  ''' '''\n",
        "  google_shared_link = 'https://drive.google.com/file/d/19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT/view?usp=sharing'\n",
        "  url = 'https://drive.google.com/uc?authuser=0&id=19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT&export=download'\n",
        "  file_id = '19lB4T32o1VbFAKRk_PExbNYV8mcZ8hRT'\n",
        "  \n",
        "  while True:\n",
        "    try:\n",
        "      with open('city.list.json', encoding=\"utf8\") as f:\n",
        "        CITIES_API = json.loads(f.read())\n",
        "      break\n",
        "    except:\n",
        "      wget.download(url)  # download the file to local google drive with the original name in the share link\n",
        "      # now can open with no path because it is in the local 'colab' directory\n",
        "  \n",
        "\n",
        "  df = pd.DataFrame(CITIES_API)\n",
        "  df = df.drop(['id', 'coord'], axis='columns')\n",
        "  df.name = df.name.str.lower()\n",
        "  df.name = df.name.str.translate(remove_punct_dict)\n",
        "\n",
        "  CITIES_API_city = sorted(set(df.name.to_list()))\n",
        "  CITIES_API_country = sorted(set(df.country.str.lower().to_list()))\n",
        "  if CITIES_API_country[0] == '':\n",
        "    CITIES_API_country = CITIES_API_country[1:]\n",
        "  CITIES_API_state = sorted(set(df.state.str.lower().to_list()))\n",
        "  if CITIES_API_state[0] == '':\n",
        "    CITIES_API_state = CITIES_API_state[1:]\n",
        "  if CITIES_API_state[0] == '00':\n",
        "    CITIES_API_state = CITIES_API_state[1:]\n",
        "  \n",
        "  df.set_index('name', inplace=True)\n",
        "  #d(df.head)\n",
        "  return df, CITIES_API_city, CITIES_API_country, CITIES_API_state\n",
        "\n",
        "df_CITIES_API, CITIES_API_city, CITIES_API_country_code, CITIES_API_state_code = load_CITIES_API()\n",
        "df_CITIES_API.head()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport re\\nimport sys\\nfrom scipy import stats\\nimport pydot\\nimport bokeh\\nimport pickle\\nimport skimage\\nfrom openpyxl import load_workbook\\nimport os\\nimport altair as alt\\nfrom sklearn.model_selection import cross_val_score\\nimport spacy\\nimport fbprophet\\nfrom statsmodels.tsa.arima_model import ARIMA\\nfrom sklearn.feature_extraction.text import TfidfVectorizer\\nimport imutils\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nimport nltk\\nimport pandas as pd\\nimport plotly.express as px\\nfrom xlrd import open_workbook\\nimport plotly as py\\nimport statistics\\nimport seaborn as sns\\nfrom sklearn import svm\\nfrom sklearn.manifold import TSNE\\nimport lightgbm as lgb\\nimport statsmodels.api as sm\\nimport matplotlib.pyplot as plt\\nimport fastai\\nimport sklearn\\nfrom scipy import signal as sg'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ḩeşāre sefīd</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‘ayn ḩalāqīm</th>\n",
              "      <td></td>\n",
              "      <td>SY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>taglag</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qabāghlū</th>\n",
              "      <td></td>\n",
              "      <td>IR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>‘arīqah</th>\n",
              "      <td></td>\n",
              "      <td>SY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             state country\n",
              "name                      \n",
              "ḩeşāre sefīd            IR\n",
              "‘ayn ḩalāqīm            SY\n",
              "taglag                  IR\n",
              "qabāghlū                IR\n",
              "‘arīqah                 SY"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u5cXlHgxKsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "0990ac3a-1087-4bab-bf8c-4109348be8c6"
      },
      "source": [
        "def load_countries():\n",
        "  path_ = path  \n",
        "  fname = 'countries.csv'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname)\n",
        "  df.Name = df.Name.str.lower()\n",
        "  COUNTRIES = df.Name.tolist()\n",
        "  df = df.set_index('Code')\n",
        "  return df, COUNTRIES\n",
        "\n",
        "countries_df, COUNTRIES = load_countries()\n",
        "countries_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Code</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AF</th>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AX</th>\n",
              "      <td>åland islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AL</th>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DZ</th>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AS</th>\n",
              "      <td>american samoa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Name\n",
              "Code                \n",
              "AF       afghanistan\n",
              "AX     åland islands\n",
              "AL           albania\n",
              "DZ           algeria\n",
              "AS    american samoa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HBp31K5KwxbJ",
        "outputId": "71892784-374f-4dce-c84f-4e35a9d09c5a"
      },
      "source": [
        "countries_df[countries_df.Name == 'israel'].index[0]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'IL'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "W1gHA85O9isU",
        "outputId": "b89c5aee-56c2-4aab-ddeb-46644c090a31"
      },
      "source": [
        "def load_cities_il():\n",
        "  path_ = path\n",
        "  fname = 'cities_IL.csv'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname, names=['city', 'district'])\n",
        "  df.city = df.city.str.translate(remove_punct_dict)\n",
        "  CITIES = df.city.tolist()\n",
        "  df = df.set_index('city')\n",
        "  return df, CITIES\n",
        "cities_il_df, CITIES_IL = load_cities_il()\n",
        "cities_il_df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>district</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>asam</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abbirim</th>\n",
              "      <td>acre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu abdun</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu ammar</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>abu amre</th>\n",
              "      <td>beersheba</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            district\n",
              "city                \n",
              "asam       beersheba\n",
              "abbirim         acre\n",
              "abu abdun  beersheba\n",
              "abu ammar  beersheba\n",
              "abu amre   beersheba"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "J-gKXG1hHu4J",
        "outputId": "ad62b875-7c89-4a3f-91f0-c8acc9af6853"
      },
      "source": [
        "def load_capitals():\n",
        "  path_ = path\n",
        "  fname = 'capitals.json'\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  CAPITALS = pd.read_json(path_ + fname, encoding=\"utf8\", typ='series').str.lower()\n",
        "\n",
        "  CAPITALS.index = CAPITALS.index.str.lower()\n",
        "  df = pd.DataFrame([CAPITALS])\n",
        "  df = df.T\n",
        "  df = df.reset_index()\n",
        "  df.columns = ['country', 'capital']\n",
        "  df = df.set_index('capital')\n",
        "  return df, CAPITALS.to_dict()\n",
        "capitals_df, CAPITALS = load_capitals()\n",
        "\n",
        "p(CAPITALS['albania'])\n",
        "p(capitals_df.loc['madrid'].country)\n",
        "capitals_df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tirana\n",
            "spain\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>kabul</th>\n",
              "      <td>afghanistan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mariehamn</th>\n",
              "      <td>åland islands</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tirana</th>\n",
              "      <td>albania</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>algiers</th>\n",
              "      <td>algeria</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pago pago</th>\n",
              "      <td>american samoa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  country\n",
              "capital                  \n",
              "kabul         afghanistan\n",
              "mariehamn   åland islands\n",
              "tirana            albania\n",
              "algiers           algeria\n",
              "pago pago  american samoa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "1YMQgZMecwVh",
        "outputId": "6c25945b-d852-4db3-cdcd-7c48cd4dc626"
      },
      "source": [
        "def load_largest():\n",
        "  fname = '100-largest-cities.csv'\n",
        "  path_ = path\n",
        "  if GIT:\n",
        "    path_ = git_path\n",
        "  df = pd.read_csv(path_ + fname, encoding='ISO-8859-8')\n",
        "  df.city = df.city.str.lower()\n",
        "  df.city = df.city.str.translate(remove_punct_dict)\n",
        "  LARGEST = df.city.tolist()\n",
        "  df = df.set_index('city')\n",
        "  return df, LARGEST\n",
        "largest_df, LARGEST = load_largest()\n",
        "\n",
        "d(largest_df.head())\n",
        "p(largest_df.loc['toronto'].country)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tokyo</th>\n",
              "      <td>Japan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delhi</th>\n",
              "      <td>India</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shanghai</th>\n",
              "      <td>China</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>so paulo</th>\n",
              "      <td>Brazil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ciudad de mxico mexico city</th>\n",
              "      <td>Mexico</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            country\n",
              "city                               \n",
              "tokyo                         Japan\n",
              "delhi                         India\n",
              "shanghai                      China\n",
              "so paulo                     Brazil\n",
              "ciudad de mxico mexico city  Mexico"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Canada\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCL5YLU-zuFS"
      },
      "source": [
        "def set_capitals():\n",
        "  # Getter that looks up the span text in the dictionary of country capitals\n",
        "  get_capital = lambda span: CAPITALS.get(span.text)\n",
        "\n",
        "  # Register the Span extension attribute \"capital\" with the getter get_capital\n",
        "  Span.set_extension(\"capital\", getter=get_capital, force=True)\n",
        "\n",
        "  # Process the text and print the entity text, label and capital attributes\n",
        "  doc = nlp(\"Czech Republic may help Slovakia protect its airspace\")\n",
        "  print([(ent.text, ent.label_, ent._.capital) for ent in doc.ents])\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb9JLByJsG9R"
      },
      "source": [
        "#nlp = en_core_web_md.load()\n",
        "def update_nlp():\n",
        "  matcher = PhraseMatcher(nlp.vocab)\n",
        "  CITIES = set(CITIES_IL + CITIES_API_city)\n",
        "\n",
        "  # disable other pipes while doing the traing to speed it up - went down from 1:40 to 0:40 minutes\n",
        "  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "  with nlp.disable_pipes(*other_pipes):\n",
        "    matcher.add(\"CITIES\", None, *list(nlp.pipe(CITIES)))\n",
        "\n",
        "  # country codes causes problems becuae many are similar to regular words (eg. 'IN' similar to 'in')\n",
        "  #matcher.add(\"CITIES_API_country_code\", None, *list(nlp.pipe(CITIES_API_country_code)))\n",
        "  # due to duplicates with country codes ('IL' = Israel, and Ilinoie), we have to check manually for states\n",
        "  #matcher.add(\"CITIES_API_state_code\", None, *list(nlp.pipe(CITIES_API_state_code)))\n",
        "\n",
        "  # Register the Span extension attributes \"is_country\" and \"is_city\" \n",
        "  check_country = lambda span: span.text.lower().translate(remove_punct_dict) in COUNTRIES\n",
        "  Span.set_extension('is_country', getter=check_country, force=True)\n",
        "\n",
        "  check_city = lambda span: span.text.lower().translate(remove_punct_dict) in CITIES\n",
        "  Span.set_extension('is_city', getter=check_city, force=True)\n",
        "\n",
        "  def gpe_component(doc):\n",
        "      # Create an entity Span with the label \"GPE\" for all matches\n",
        "      matches = matcher(doc)\n",
        "      doc.ents = [Span(doc, start, end, label=\"GPE\") for match_id, start, end in matches]\n",
        "      return doc\n",
        "\n",
        "  # Add the component to the pipeline\n",
        "  pipes = nlp.pipe_names\n",
        "  if 'gpe_component' in pipes:\n",
        "    nlp.remove_pipe('gpe_component')\n",
        "\n",
        "  nlp.add_pipe(gpe_component, first=True)\n",
        "  #print(nlp.pipe_names)\n",
        "\n",
        "update_nlp()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLqojifIudRU"
      },
      "source": [
        "# Get Parts (POS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFIUD4FCXyUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcb00db-41da-439c-85bb-e03956d5062a"
      },
      "source": [
        "def get_parts(text, disp=False, verbose=True):\n",
        "  global DEBUG\n",
        "  doc = nlp(text.lower().translate(remove_punct_dict))\n",
        "  date, gpe, ents = [], {}, []\n",
        "  action = ''\n",
        "  multiple_cities = False\n",
        "  if disp: p()\n",
        "  for token in doc:\n",
        "    if disp:\n",
        "      p(f'{token.text}, dep_={token.dep_}, ent_type={token.ent_type_}, head={token.head}, lemma_={token.lemma_}, pos_={token.pos_}, tag_={token.tag_}')\n",
        "    if token.ent_type_ == 'GPE': ents.append((token.text.lower(), token))\n",
        "  for entity in doc.ents:\n",
        "      if disp:\n",
        "        print(f\"{entity.text}, {entity.label_}='{spacy.explain(entity.label_)}', is_city={entity._.is_city}, is_country={entity._.is_country}\")\n",
        "      ent_text = entity.text.lower().translate(remove_punct_dict)\n",
        "      if entity.label_ == 'DATE': date.append(ent_text)\n",
        "      if entity.label_ == 'GPE':\n",
        "        token = None\n",
        "        for e in ents:\n",
        "          if ent_text == e[0]:\n",
        "            token = e[1] \n",
        "            break\n",
        "        # verify the GPE is a true GPE for cases that a city has a name that has another meaninig\n",
        "        if token and token.text != token.lemma_: # a true GPE cannot be lemmatized\n",
        "          continue\n",
        "        # for example there is a city in Denemark that has a name 'rain'\n",
        "        if token and len(ents) > 1 and (token.head == token or token.pos_ not in ['PROPN', 'PRON', 'NOUN']) and not entity._.is_country:\n",
        "          valid_gpe = False\n",
        "          for e in ents:\n",
        "            if ent_text != e[0]:\n",
        "              tk = e[1]\n",
        "              if tk.head == token:  # the token is connected to another gpe, so it is a valid gpe (for example, (paris, canada) are connected\n",
        "                valid_gpe = True\n",
        "                break\n",
        "          if not valid_gpe:\n",
        "            if DEBUG: p('A:', ent_text)\n",
        "            continue\n",
        "        ent_type = 'state'\n",
        "        if DEBUG: p('0:', ent_text, entity._.is_city, entity._.is_country)\n",
        "        if entity._.is_city and not entity._.is_country: # 'canada' is a country and also a city in Portugal\n",
        "          ent_type = 'city'\n",
        "          if ent_text in df_CITIES_API.index.values: \n",
        "            code_country = df_CITIES_API.loc[ent_text].country\n",
        "            if type(code_country) != str:\n",
        "              multiple_cities = True\n",
        "              ent_country = countries_df.loc[code_country[0]].Name\n",
        "            else:\n",
        "              ent_country = countries_df.loc[code_country].Name\n",
        "          elif ent_text in CITIES_IL:\n",
        "            ent_country = 'israel'\n",
        "          else:\n",
        "            ent_country = ''\n",
        "        elif entity._.is_country or ent_text in CITIES_API_country_code:\n",
        "          ent_type = 'country'\n",
        "\n",
        "        if ent_type not in gpe:\n",
        "          gpe[ent_type] = []\n",
        "        if ent_type == 'city':\n",
        "           gpe[ent_type].append((entity.text, ent_country))\n",
        "        else:\n",
        "          gpe[ent_type].append(entity.text)\n",
        "  if len(date) == 0:\n",
        "    date = 'current'\n",
        "\n",
        "  if DEBUG: p('1:', multiple_cities, gpe)\n",
        "  if multiple_cities or ('city' in gpe and len(gpe['city']) > 1):\n",
        "    if 'country' in gpe:\n",
        "      # verify country code of the city is correct, when there multiple cities\n",
        "      for i, (city, city_country) in enumerate(gpe['city']):\n",
        "        country = gpe['country'][0]\n",
        "        if city_country != country:\n",
        "          for code_country in df_CITIES_API.loc[city].country:\n",
        "            if city_country == countries_df.loc[code_country].Name:\n",
        "              # found a matching country\n",
        "              gpe['city'][i] = (city, country)\n",
        "              break\n",
        "    else:\n",
        "      check_capital = True\n",
        "      if len(gpe['city']) == 2: # maybe enter a country which has city with that name (eg. Toronto, US = there is a city name 'us' in france and 'usa' in japan)\n",
        "        # 'city': [('toronto', 'Canada'), ('us', 'france')]\n",
        "        for i in range(1,-1,-1):\n",
        "          city = gpe['city'][i][0].upper()\n",
        "          if city in countries_df.index: #usually the 2nd \"city\" is the country\n",
        "            city_country = countries_df.loc[city].Name\n",
        "            j = 0 if i == 1 else 1\n",
        "            gpe['city'] = (gpe['city'][j][0], city_country)\n",
        "            gpe['country'] = city_country\n",
        "            check_capital = False\n",
        "            break\n",
        "      if check_capital:\n",
        "        # check if one of the cities is a capital or a large city, then use it\n",
        "        for i, (city, city_country) in enumerate(gpe['city']):\n",
        "          if city in capitals_df.index.values:\n",
        "            # found a matching country\n",
        "            city_country = capitals_df.loc[city].country\n",
        "            gpe['city'][i] = (city, city_country)\n",
        "            break\n",
        "          if city in largest_df.index.values:\n",
        "            # found a matching country\n",
        "            city_country = largest_df.loc[city].country\n",
        "            gpe['city'][i] = (city, city_country)\n",
        "            break\n",
        "  elif 'country' in gpe and 'city' in gpe:  # country with city, verify correct\n",
        "      # verify country code of the city is correct, when user entered \n",
        "      city, city_country = gpe['city'][0]\n",
        "      country = gpe['country'][0]\n",
        "      if city_country != country:\n",
        "        gpe['city'] = [(city, f'ERROR: city [{city}] not found in country [{country}] - try a different spelling of the city')]\n",
        "  elif 'country' in gpe and 'city' not in gpe:  # country without city, get the capital\n",
        "    country = gpe['country'][0]\n",
        "    if country in CAPITALS:\n",
        "      gpe['city'] = [(CAPITALS[country], country)]\n",
        "  result = {}\n",
        "  result['date'] = date\n",
        "  result.update(gpe)\n",
        "  if disp:\n",
        "    p(result)\n",
        "  elif verbose and 'city' not in result:\n",
        "    p(f'FAILED: org [{text}], {result}')\n",
        "  return result\n",
        "\n",
        "DEBUG = False\n",
        "if False and TEST:\n",
        "  get_parts(\"Today weather in a Ra-anana\")\n",
        "  get_parts(\"Today weather in a Ra'anana\")  \n",
        "  get_parts(\"Today weather in a Raanana\")\n",
        "  get_parts(\"weather in toronto\") # there is a city toronto in USA and toronto is not the capital of Canada so we take the first city in the db\n",
        "  get_parts(\"weather in toronto, canada\")\n",
        "  get_parts(\"weather paris next 5 days\")\n",
        "  get_parts(\"tell me how is the weather in the ra- anana in the\")\n",
        "  get_parts(\"rain in toronto\")\n",
        "get_parts(\"weather in toronto, us\")\n",
        "get_parts(\"weather in toronto, canada\")\n",
        "get_parts(\"weather in jenin\")\n",
        "get_parts(\"weather in jenin, israel\")\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('jenin',\n",
              "   'ERROR: city [jenin] not found in country [israel] - try a different spelling of the city')],\n",
              " 'country': ['israel'],\n",
              " 'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwaYy7z-8vfo",
        "outputId": "f1619c82-1049-4feb-862c-28ef798e9272"
      },
      "source": [
        "get_parts(\"please tell me if it will rain tonight in Rain\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FAILED: org [please tell me if it will rain tonight in Rain], {'date': 'current'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQv631Mpz7Xw",
        "outputId": "0c75cdf6-647d-4d13-ea1b-e439a80dc6f7"
      },
      "source": [
        "DEBUG = False\n",
        "get_parts(\"tomorrow and today rain in spain\")\n",
        "get_parts(\"tomorrow rain in madrid\")\n",
        "get_parts(\"tomorrow rain in beersheba\")\n",
        "get_parts(\"tomorrow rain in israel\")\n",
        "get_parts(\"weather paris Canada\")\n",
        "get_parts(\"weather paris, Canada\")\n",
        "get_parts(\"tomorrow rain in yafo\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('yafo', 'israel')], 'date': ['tomorrow']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcfVvMeRddoX"
      },
      "source": [
        "if TEST:\n",
        "  get_parts(\"Today weather in a Ra-anana\")\n",
        "  get_parts(\"weather in tel aviv\")\n",
        "  get_parts(\"tomorrow weather in haifa\")\n",
        "  get_parts(\"tomorrow rain in beersheba\")\n",
        "  get_parts(\"weather paris today and tomorrow\")\n",
        "  get_parts(\"weather paris\")\n",
        "  get_parts(\"weather paris in December\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ob4yr4F2eu5e",
        "outputId": "1228054f-ec60-421f-b773-c63039e5b79f"
      },
      "source": [
        "get_parts(\"ra'anana\")\n",
        "get_parts(\"Today weather in a Tel Aviv\")\n",
        "get_parts(\"weather paris\")\n",
        "get_parts(\"paris weather \")\n",
        "get_parts('Paris weather in')\n",
        "get_parts(\"weather shelomi\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'city': [('shelomi', 'israel')], 'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtB-Itaok9Br"
      },
      "source": [
        "# Run the bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "4OiSqiCC9wy7",
        "outputId": "497843f6-1d9e-424c-9e98-45f7378ed3d4"
      },
      "source": [
        "nltk.download(['punkt', 'stopwords'])\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport nltk'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd\\nimport nltk'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2lBe7UTUhfO"
      },
      "source": [
        "> when similarity was .075 it matched the sentence\n",
        "\n",
        ">\"tell me how is the weather in the ra- anana in the\"\n",
        "\n",
        ">to \"what's up\" of tag [\"greeting\"] so we increased it to 0.85"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6T_HYP7seLq"
      },
      "source": [
        "## Google search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ry8ASR8NEdKi",
        "outputId": "f21bdef3-3abb-4a15-a348-4efb1002aae1"
      },
      "source": [
        "import bs4\n",
        "def get_google(text):\n",
        "  url = \"https://google.com/search?q=\" + text + '&hl=en'\n",
        "  request_result = requests.get( url )\n",
        "  soup = bs4.BeautifulSoup(request_result.text, \"html.parser\")\n",
        "  spans = soup.find_all('span', class_='BNeawe')\n",
        "  new_text = ''\n",
        "  for span in spans: \n",
        "    if isinstance(span.contents[0], bs4.NavigableString):\n",
        "      new_text += str(span.contents[0]) + ' '\n",
        "  return new_text\n",
        "get_google(\"weather ra anana\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Ra'anana, Israel  /  Weather \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry23BUN9weHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8331e13-4405-42ed-8d94-9369e1f199d5"
      },
      "source": [
        "do = True\n",
        "GREETING, NOANSWER = 0, 3\n",
        "p(intents['intents'][GREETING]['responses'][0])\n",
        "min_similarity = 0.84\n",
        "VERBOSE = 0\n",
        "\n",
        "while do:\n",
        "  user_msg = input().lower().strip()\n",
        "  if user_msg == '':\n",
        "    answers = intents['intents'][NOANSWER]['responses']\n",
        "    p(\"WeatherBot: \" + random.choice(answers))\n",
        "    continue\n",
        "  round = 0\n",
        "  answer = ''\n",
        "  org_msg = user_msg\n",
        "  while round < 3 and do:\n",
        "    if VERBOSE:   p(f'round {round}: {user_msg}')\n",
        "    doc1 = nlp(user_msg)\n",
        "    answers, tag = None, None\n",
        "    top_similarity = 0\n",
        "    # verify not an erroeous finding (if we have GPE in the doc we assume it is not a general request)\n",
        "    if len([ent for ent in doc1.ents if ent.label_ == 'GPE']) == 0:\n",
        "      for ints in intents['intents']:\n",
        "        #p(ints)\n",
        "        for text in ints['patterns']:\n",
        "          doc2 = nlp(text)\n",
        "          # Get the similarity of doc1 and doc2\n",
        "          similarity = doc1.similarity(doc2)\n",
        "          if VERBOSE > 2: p(f\"{similarity}, {doc2}, {[ints['tag']]}\")\n",
        "          if similarity > top_similarity:\n",
        "            top_similarity = similarity\n",
        "            answers = ints['responses']\n",
        "            tag = ints['tag']\n",
        "    #  p(top_similarity, tag)\n",
        "    #  p(answers)\n",
        "      if top_similarity > min_similarity:\n",
        "        if tag == \"goodbye\":\n",
        "          do = False\n",
        "        if tag in [\"goodbye\", \"greeting\", \"thanks\", \"options\"]:\n",
        "          answer = random.choice(answers)\n",
        "          break\n",
        "    parts = get_parts(user_msg, VERBOSE > 1, False)\n",
        "    if VERBOSE:  p(parts)\n",
        "    if 'date' in parts and 'city' in parts and 'ERROR' not in parts['city'][0][1]:\n",
        "      #p(parts['city'][0][0])\n",
        "      answer = get_weather(parts['date'], parts['city'], action=None)\n",
        "    elif 'city' in parts and 'ERROR' in parts['city'][0][1]:\n",
        "      answer = parts['city'][0][1]\n",
        "    elif round == 0:\n",
        "      round = 1\n",
        "      user_msg = ''\n",
        "      space = ' '\n",
        "      for token in doc1:\n",
        "        if token.text in stopwords: continue\n",
        "        text = token.text.lower().translate(remove_punct_dict)\n",
        "        if text == '': continue\n",
        "        if text[-1] == '-': # take care of 'ra- anana'\n",
        "          user_msg += space + text[:-1]\n",
        "          space = ''\n",
        "        else:\n",
        "          user_msg += space + text\n",
        "          space = ' '\n",
        "      continue\n",
        "    elif round == 1:\n",
        "      round = 2\n",
        "      user_msg = get_google(org_msg)\n",
        "      if user_msg != '':\n",
        "        continue\n",
        "    break\n",
        "  if answer == '': answer = \"You need to tell me a city to check (maybe spell in differently)\"\n",
        "  p(f\"WeatherBot: {answer}\")\n",
        "# weather in jenin, israel  "
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi. My name is WeatherBot and I'm a chatbot. If you want to exit, type 'Bye' If you want help type 'Help'\n",
            "weather in TelAviv\n",
            "WeatherBot: In Jerusalem, Israel the current weather is: clear sky\n",
            "weather ra- anana\n",
            "WeatherBot: In Raanana, Israel the current weather is: clear sky\n",
            "tell me how is the weather in the ra- anana in the\n",
            "WeatherBot: In Raanana, Israel the current weather is: clear sky\n",
            "bye\n",
            "WeatherBot: Bye! Come back again soon.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAr4WaLVDL2x",
        "outputId": "0b2c15fd-b685-4dac-ed14-12541381609e"
      },
      "source": [
        "# example of successful chat although get parts faile\n",
        "get_parts(\"weather in tel-aviv\")\n",
        "get_parts(\"weather in TelAviv\")   # gave answer for Israel/Jerusalem\n",
        "get_parts(\"what is tel aviv\")\n",
        "get_parts(\"wether in tel aviv\")\n",
        "get_parts(\"please tell me if it will rain tonight in Rain\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FAILED: org [weather in tel-aviv], {'date': 'current'}\n",
            "FAILED: org [weather in TelAviv], {'date': 'current'}\n",
            "FAILED: org [please tell me if it will rain tonight in Rain], {'date': 'current'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAH-c7izF8YF",
        "outputId": "28804af0-cc61-4d2c-fa36-9ed63ee4ab4c"
      },
      "source": [
        "# fixed in round1 of the bot (remove stop words and dashes followed by a space '- ')\n",
        "get_parts(\"weather ra- anana\") # for google\n",
        "get_parts(\"tell me how is the weather in the ra- anana in the\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FAILED: org [weather ra- anana], {'date': 'current'}\n",
            "FAILED: org [tell me how is the weather in the ra- anana in the], {'date': 'current'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': 'current'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwK8AS5vcuCq"
      },
      "source": [
        "# TODO:\n",
        "\n",
        "1. DONE: display country when getting result of weather so the user knows it is the right country - if there multiple cities\n",
        "\n",
        "2. DONE: load jsons from github - (one file too large so download it from a shared goole link on my google drive)\n",
        "\n",
        "3. Use flask\n",
        "\n",
        "4. DONE: if fails to understand try round 2 - removing stop words (punctuation akready done by spacy), then round 3 use google to try to fix typo mistake and only if all fails display a message to user\n",
        "\n",
        "5. To identify if it is a question or not - must be question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKZtAV4zK0Ud"
      },
      "source": [
        "# QUESTION:\n",
        "\n",
        "2. Are we to handle 'Ra-anana'? we handle 'Raanana'\n",
        "3. DONE - There is a city toronto in USA and toronto is not the capital of Canada so we take the first city in the db (we check now if it is one of the 100 largest cities in the world)"
      ]
    }
  ]
}